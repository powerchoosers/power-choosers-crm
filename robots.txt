# robots.txt for nodalpoint.io
# Updated: January 2026

# Default rules for all search engines
User-agent: *
Allow: /
Allow: /philosophy
Allow: /bill-debugger
Allow: /technical-docs
Allow: /market-data

# Block platform/private areas and API endpoints
Disallow: /network/
Disallow: /login
Disallow: /api/
Disallow: /scripts/
Disallow: /styles/
Disallow: /test
Disallow: /test-
Disallow: /algolia-reindex.html
Disallow: /unsubscribe.html
Disallow: /node_modules/
Disallow: /backups/
Disallow: /Uploaded Leads/
Disallow: /crm-dashboard.html

# Block JavaScript and JSON files (not needed for SEO)
Disallow: /*.js$
Disallow: /*.json$

# Google-specific rules
User-agent: Googlebot
Allow: /
Disallow: /network/
Disallow: /api/

# Bing-specific rules
User-agent: Bingbot
Allow: /
Disallow: /network/
Disallow: /api/

# AI Search Engine Crawlers
User-agent: GPTBot
User-agent: ChatGPT-User
User-agent: CCBot
User-agent: anthropic-ai
User-agent: Claude-Web
User-agent: PerplexityBot
Allow: /
Disallow: /network/
Disallow: /api/

# Crawl-delay to prevent server overload (1 second)
User-agent: *
Crawl-delay: 1

# Sitemap location
Sitemap: https://nodalpoint.io/sitemap.xml






